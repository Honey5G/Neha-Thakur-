{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Assignment Code: DA-AG-011"
      ],
      "metadata": {
        "id": "Ia5CGb1CbT85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment- Logistic Regression"
      ],
      "metadata": {
        "id": "4A1sGSMUbVDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques.1 What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?"
      ],
      "metadata": {
        "id": "E1lXGMBZbenv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: Logistic Regression is a classification algorithm used to predict the probability of a binary outcome (e.g., 0 or 1, Yes or No, True or False). It uses a logistic function (sigmoid function) to map the output of a linear equation to a probability value between 0 and 1.\n",
        "\n",
        "Here's how it differs from Linear Regression:\n",
        "\n",
        "Purpose: Linear Regression is used for predicting continuous numerical values, while Logistic Regression is used for predicting categorical outcomes (specifically binary outcomes).\n",
        "Output: Linear Regression outputs a continuous value, while Logistic Regression outputs a probability between 0 and 1.\n",
        "Function: Linear Regression uses a linear function (y = mx + c), while Logistic Regression uses the sigmoid function to transform the output of a linear equation into a probability.\n",
        "Cost Function: Linear Regression typically uses Mean Squared Error (MSE) as its cost function, while Logistic Regression uses log loss (also known as cross-entropy).\n",
        "Decision Boundary: Linear Regression doesn't have a decision boundary. Logistic Regression has a decision boundary (usually at a probability of 0.5) to classify the output into one of the two categories."
      ],
      "metadata": {
        "id": "lbreFANqbsOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques.2 Explain the role of the Sigmoid function in Logistic Regression?"
      ],
      "metadata": {
        "id": "I2DITBrxbuOX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:"
      ],
      "metadata": {
        "id": "ha_CQYa-bzgh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f7bc7f4"
      },
      "source": [
        "Ans: The Sigmoid function (also known as the logistic function) plays a crucial role in Logistic Regression. Its purpose is to map the output of the linear equation to a probability value between 0 and 1.\n",
        "\n",
        "Here's a breakdown of its role:\n",
        "\n",
        "1.  **Transformation:** The Sigmoid function takes any real-valued number as input and transforms it into a value between 0 and 1. This is essential because we want to predict a probability, which must lie within this range.\n",
        "2.  **Probability Interpretation:** The output of the Sigmoid function can be interpreted as the probability that the input belongs to a particular class (usually the positive class). A value close to 1 indicates a high probability of belonging to the positive class, while a value close to 0 indicates a high probability of belonging to the negative class.\n",
        "3.  **Decision Boundary:** The Sigmoid function helps in establishing a decision boundary. By default, if the output of the Sigmoid function is greater than or equal to 0.5, the prediction is classified as the positive class, and if it's less than 0.5, it's classified as the negative class.\n",
        "\n",
        "Essentially, the Sigmoid function provides a smooth transition between the linear output and the probability output, making it suitable for binary classification problems."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques.3 What is Regularization in Logistic Regression and why is it needed?"
      ],
      "metadata": {
        "id": "ZjtmlezDb8T1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: Regularization in Logistic Regression is a technique used to prevent overfitting. Overfitting occurs when the model learns the training data too well, including the noise and outliers, which results in poor performance on unseen data.\n",
        "\n",
        "Regularization adds a penalty term to the cost function that the model tries to minimize during training. This penalty discourages the model from assigning excessively large weights to the features. By shrinking the weights, regularization makes the model simpler and less sensitive to small fluctuations in the training data, thus improving its ability to generalize to new data.\n",
        "\n",
        "There are two common types of regularization used in Logistic Regression:\n",
        "\n",
        "L1 Regularization (Lasso): Adds a penalty proportional to the absolute value of the weights. This can lead to some weights becoming exactly zero, effectively performing feature selection.\n",
        "L2 Regularization (Ridge): Adds a penalty proportional to the square of the weights. This shrinks the weights towards zero but rarely makes them exactly zero.\n",
        "Regularization is needed in Logistic Regression to:\n",
        "\n",
        "Prevent Overfitting: The primary reason is to prevent the model from becoming too complex and performing poorly on new, unseen data.\n",
        "Reduce Variance: Regularization helps reduce the variance of the model, making it more stable and less sensitive to changes in the training data.\n",
        "Handle Multicollinearity: In cases where features are highly correlated, regularization can help stabilize the model and prevent issues caused by multicollinearity."
      ],
      "metadata": {
        "id": "cQpeC3IdcJYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques.4 What are some common evaluation metrics for classification models, and\n",
        "why are they important?"
      ],
      "metadata": {
        "id": "aiYVaLhscSpI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: There are several common evaluation metrics for classification models, and they are crucial for understanding how well your model is performing. Here are some of the key ones and why they are important:\n",
        "\n",
        "Accuracy:\n",
        "What it is: The proportion of correctly predicted instances out of the total number of instances.\n",
        "Why it's important: It provides a general measure of the model's overall correctness. However, it can be misleading in cases of imbalanced datasets (where one class is significantly more frequent than the other).\n",
        "Precision:\n",
        "What it is: The proportion of true positive predictions among all positive predictions (true positives + false positives). It answers the question: \"Of all the instances predicted as positive, how many were actually positive?\"\n",
        "Why it's important: It is important when the cost of a false positive is high. For example, in medical diagnosis, a false positive could lead to unnecessary treatment.\n",
        "Recall (Sensitivity or True Positive Rate):\n",
        "What it is: The proportion of true positive predictions among all actual positive instances (true positives + false negatives). It answers the question: \"Of all the actual positive instances, how many were correctly predicted as positive?\"\n",
        "Why it's important: It is important when the cost of a false negative is high. For example, in fraud detection, a false negative means a fraudulent transaction is missed.\n",
        "F1-Score:\n",
        "What it is: The harmonic mean of precision and recall. It provides a balance between precision and recall.\n",
        "Why it's important: It is useful when you need to consider both precision and recall and want a single metric to evaluate the model's performance, especially in cases of imbalanced datasets.\n",
        "Confusion Matrix:\n",
        "What it is: A table that summarizes the performance of a classification model by showing the counts of true positives, true negatives, false positives, and false negatives.\n",
        "Why it's important: It provides a detailed breakdown of the model's predictions and allows you to calculate other metrics like precision, recall, and accuracy. It helps you understand where the model is making mistakes.\n",
        "ROC Curve and AUC:\n",
        "What it is: The Receiver Operating Characteristic (ROC) curve is a plot that shows the trade-off between the True Positive Rate (Recall) and the False Positive Rate (1 - Specificity) at various threshold settings. The Area Under the Curve (AUC) is a single value that summarizes the overall performance of the model across all possible thresholds.\n",
        "Why it's important: It is useful for evaluating the model's ability to distinguish between the two classes. A higher AUC indicates better performance."
      ],
      "metadata": {
        "id": "EeSj9aKUcYnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques.5 Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "(Use Dataset from sklearn package)\n"
      ],
      "metadata": {
        "id": "4C9D8JjscjO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c-3Jr9uEcqds"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "682ad8ee",
        "outputId": "b3923b84-edc0-4513-b0a3-71182f7bb9e4"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load a sample dataset from scikit-learn (e.g., Iris dataset)\n",
        "# If you have a CSV file, you would use:\n",
        "# df = pd.read_csv('your_dataset.csv')\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target, name='target')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy of the Logistic Regression model: {accuracy:.2f}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Logistic Regression model: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques.6 Write a Python program to train a Logistic Regression model using L2\n",
        "regularization (Ridge) and print the model coefficients and accuracy?"
      ],
      "metadata": {
        "id": "i5NXwM07c3GZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:"
      ],
      "metadata": {
        "id": "sN89uqYJc9NX"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e3f4af9",
        "outputId": "ebc8a8f5-b1a1-4285-8cc3-7c55f461fc02"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize and train the Logistic Regression model with L2 regularization\n",
        "# The default penalty in LogisticRegression is 'l2'\n",
        "model_l2 = LogisticRegression(penalty='l2')\n",
        "model_l2.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_l2 = model_l2.predict(X_test)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy_l2 = accuracy_score(y_test, y_pred_l2)\n",
        "print(f\"Accuracy of the Logistic Regression model with L2 regularization: {accuracy_l2:.2f}\")\n",
        "\n",
        "# Print the model coefficients\n",
        "print(\"\\nModel Coefficients (L2 regularization):\")\n",
        "# For multi-class classification, coefficients are per class\n",
        "if len(model_l2.coef_) > 1:\n",
        "    for i, coef in enumerate(model_l2.coef_):\n",
        "        print(f\"Class {model_l2.classes_[i]}: {coef}\")\n",
        "else:\n",
        "    print(model_l2.coef_[0])\n",
        "\n",
        "# Print the intercept\n",
        "print(f\"\\nModel Intercept (L2 regularization): {model_l2.intercept_}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Logistic Regression model with L2 regularization: 1.00\n",
            "\n",
            "Model Coefficients (L2 regularization):\n",
            "Class 0: [-0.39345607  0.96251768 -2.37512436 -0.99874594]\n",
            "Class 1: [ 0.50843279 -0.25482714 -0.21301129 -0.77574766]\n",
            "Class 2: [-0.11497673 -0.70769055  2.58813565  1.7744936 ]\n",
            "\n",
            "Model Intercept (L2 regularization): [  9.00884295   1.86902164 -10.87786459]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques.7 Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report?\n"
      ],
      "metadata": {
        "id": "rCL7uW1OdADk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2efe7cb5",
        "outputId": "92e47e3b-8b68-466e-c307-ff3480b295de"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize and train the Logistic Regression model with multi_class='ovr'\n",
        "# The 'ovr' strategy trains a separate binary classifier for each class\n",
        "model_ovr = LogisticRegression(multi_class='ovr', solver='liblinear') # 'liblinear' is often suitable for 'ovr' with smaller datasets\n",
        "\n",
        "# Fit the model\n",
        "model_ovr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_ovr = model_ovr.predict(X_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report (multi_class='ovr'):\")\n",
        "print(classification_report(y_test, y_pred_ovr))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (multi_class='ovr'):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques.8 Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "accuracy?\n"
      ],
      "metadata": {
        "id": "0tC_dMqqdTzd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d0e78f9",
        "outputId": "c9a4721e-94cc-41f5-9636-8291ff01b023"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the parameter grid to search\n",
        "# 'C' is the inverse of regularization strength; smaller values specify stronger regularization.\n",
        "# 'penalty' can be 'l1', 'l2', 'elasticnet', or 'none'. 'elasticnet' requires 'solver' to be 'saga'.\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "# Use a solver that supports both l1 and l2 penalties, like 'liblinear' or 'saga'\n",
        "# 'liblinear' is generally good for smaller datasets and supports l1/l2.\n",
        "# 'saga' is good for larger datasets and supports l1, l2, elasticnet, and none penalties.\n",
        "# For this example with l1 and l2, 'liblinear' is a good choice.\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "# cv=5 means 5-fold cross-validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and best score (validation accuracy)\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy: {:.2f}\".format(grid_search.best_score_))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'C': 10, 'penalty': 'l1'}\n",
            "Best cross-validation accuracy: 0.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques.9 : Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling?\n"
      ],
      "metadata": {
        "id": "1gRENv7Vdg2w"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afc2ebfd",
        "outputId": "7a4478f2-f90b-40ce-bfe8-cb90263b6828"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform both training and testing data\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize and train the Logistic Regression model on scaled data\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "\n",
        "# Calculate and print the accuracy of the scaled model\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy of the Logistic Regression model with scaling: {accuracy_scaled:.2f}\")\n",
        "\n",
        "# Compare with the accuracy of the model without scaling (assuming 'accuracy' variable exists from previous steps)\n",
        "# If the 'accuracy' variable is not available, you would need to re-calculate it here\n",
        "try:\n",
        "    print(f\"Accuracy of the Logistic Regression model without scaling: {accuracy:.2f}\")\n",
        "except NameError:\n",
        "    print(\"Accuracy of the model without scaling is not available in this session.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Logistic Regression model with scaling: 1.00\n",
            "Accuracy of the Logistic Regression model without scaling: 1.00\n"
          ]
        }
      ]
    }
  ]
}